{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Achar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Achar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Achar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importation des packages nécessaires\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import nltk.corpus\n",
    "import re\n",
    "import functools\n",
    "import operator\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dataFrame contenant les données de Joe Biden\n",
    "df_biden = pd.read_csv('hashtag_joebiden.csv', lineterminator='\\n')\n",
    "df_biden['mention'] = 'Biden'\n",
    "\n",
    "# Création du DataFrame contenant les données de Donald Trump\n",
    "df_trump = pd.read_csv('hashtag_donaldtrump.csv', lineterminator='\\n')\n",
    "df_trump['mention'] = 'Trump'\n",
    "\n",
    "# Concaténation des deux DataFrames en un seul\n",
    "df_full = [df_trump,df_biden]\n",
    "df_full = pd.concat(df_full)\n",
    "\n",
    "# Identification des tweets mentionnant les deux candidats (duplicatas)\n",
    "df_full['duplicated'] = df_full.duplicated(subset='tweet', keep=False)\n",
    "df_full.loc[(df_full['duplicated'] == True),'mention'] = 'Trump & Biden'\n",
    "\n",
    "#conversion des dates en datetime\n",
    "df_full['created_at'] = pd.to_datetime(df_full[\"created_at\"])\n",
    "df_full.sort_values('created_at', inplace=True)\n",
    "\n",
    "#Retrait des heures pour pouvoir regrouper les dates plus facilement\n",
    "df_full['created_at'] = pd.to_datetime(df_full[\"created_at\"]).dt.date\n",
    "\n",
    "#Conversion des likes en int\n",
    "df_full['likes'] = df_full['likes'].astype(int)\n",
    "\n",
    "# Suppression des doublons\n",
    "df_full = df_full.drop_duplicates(subset='tweet').reset_index(drop=True)\n",
    "\n",
    "# Modification du Dataframe des candidats pour ne contenir que les tweets mentionnant uniquement ceux-ci\n",
    "df_trump = df_full.loc[df_full['mention'] == 'Trump']\n",
    "df_biden = df_full.loc[df_full['mention'] == 'Biden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compte par continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countplot = sns.catplot(kind='count',x='continent', data=df_full.sort_values('mention'), hue='mention')\n",
    "countplot.set_xticklabels(rotation=80)\n",
    "colors = ['#258BF3','#25F347','#F1120B']\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "countplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mots préférés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Déclaration d'une fonction pour nettoyer le texte des tweets\n",
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    \n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    \n",
    "    # Nettoyage du texte des tweets\n",
    "    # Remplacement par '' de toutes les mentions @xyz, sites webs et caractères non compris entre a-z ou A-Z ou 0-9\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    \n",
    "    # Remplacement par '' de tous les nombres\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Définition d'une fonction pour lemmatiser le texte (trouver la racine des mots)\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "\n",
    "# Définition d'une fonction pour afficher le word cloud en fonction des paramètres choisis\n",
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dataframe ne contenant que les tweets de Trump provenants des États-Unis\n",
    "trump_tweet_usa = df_trump[df_trump['country'] == 'United States of America'][['tweet']]\n",
    "\n",
    "# Nettoyage des tweets de Trump aux USA et affichage des premières lignes\n",
    "data_clean = clean_text(trump_tweet_usa, 'tweet', 'tweet_clean')\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une variable qui contient les 'stopwords' anglais, \n",
    "# c-à-d les mots non-essentiels, qui seront à retirer (you, a, I, etc...)\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Retrait de tous les stopwords et ajout dans une nouvelle série sous le nom tweet_clean\n",
    "data_clean['tweet_clean'] = data_clean['tweet_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création d'une liste de tokens à évaluer pour chaque tweet (découpage de chaque mot) \n",
    "# et ajout au df sous le nom tweet_tokens\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data_clean['tweet_tokens'] = data_clean['tweet_clean'].apply(lambda x: word_tokenize(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatisation des tweets et ajout au df sous le nom tweet_tokens_lemma\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "data_clean['tweet_tokens_lemma'] = data_clean['tweet_tokens'].apply(lambda x: word_lemmatizer(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Transformation des tweet_tokens_lemma (liste de listes) en liste applatie\n",
    "trump_token_list = functools.reduce(operator.iconcat, data_clean['tweet_tokens_lemma'].values.tolist(), [])\n",
    "\n",
    "# Transformation de la liste applatie en string\n",
    "trump_token_string = ' '.join(trump_token_list)\n",
    "\n",
    "# Choix du masque à utiliser pour Trump\n",
    "mask_trump = np.array(Image.open('donaldtrump_mask.png'))\n",
    "\n",
    "# Définition des paramètres du wordcloud\n",
    "wordcloud_trump = WordCloud(background_color = 'black', random_state=1,\n",
    "                      colormap='Reds', collocations=False,\n",
    "                      mask=mask_trump, contour_color='white').generate(trump_token_string)\n",
    "\n",
    "# Traçage du word cloud et aperçu de l'image\n",
    "trump_plot = plot_cloud(wordcloud_trump)\n",
    "trump_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dataframe ne contenant que les tweets de TBiden provenants des États-Unis\n",
    "biden_tweet_usa = df_biden[df_biden['country'] == 'United States of America'][['tweet']]\n",
    "\n",
    "# Nettoyage des tweets de Biden aux USA à l'aide de la fonction précédemment définie\n",
    "data_clean = clean_text(biden_tweet_usa, 'tweet', 'tweet_clean')\n",
    "\n",
    "# Retrait de tous les stopwords et ajout dans une nouvelle série sous le nom tweet_clean\n",
    "data_clean['tweet_clean'] = data_clean['tweet_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Création d'une liste de tokens à évaluer pour chaque tweet (découpage de chaque mot) \n",
    "# et ajout au df sous le nom tweet_tokens\n",
    "data_clean['tweet_tokens'] = data_clean['tweet_clean'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Lemmatisation des tweets et ajout au df sous le nom tweet_tokens_lemma\n",
    "data_clean['tweet_tokens_lemma'] = data_clean['tweet_tokens'].apply(lambda x: word_lemmatizer(x))\n",
    "\n",
    "# Transformation des tweet_tokens_lemma (liste de listes) en liste applatie\n",
    "biden_token_list = functools.reduce(operator.iconcat, data_clean['tweet_tokens_lemma'].values.tolist(), [])\n",
    "\n",
    "# Transformation de la liste applatie en string\n",
    "biden_token_string = ' '.join(biden_token_list)\n",
    "\n",
    "# Choix du masque à utiliser pour Biden\n",
    "mask_biden = np.array(Image.open('joebiden_mask.png'))\n",
    "\n",
    "# Définition des paramètres du wordcloud\n",
    "wordcloud_biden = WordCloud(background_color = 'black', random_state=1,\n",
    "                      colormap='Blues', collocations=False,\n",
    "                      mask=mask_biden, contour_color='white').generate(biden_token_string)\n",
    "\n",
    "# Traçage du word cloud\n",
    "biden_plot = plot_cloud(wordcloud_biden)\n",
    "biden_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisation côte-à-côte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une figure pour contenir les 2 images\n",
    "fig = plt.figure(figsize=(20,20), facecolor = 'black')\n",
    "\n",
    "# Paramétrage de la première sous-figure\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.axis(\"off\")\n",
    "ax1.imshow(wordcloud_biden)\n",
    "\n",
    "# Paramétrage de la deuxième sous-figure\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.axis(\"off\")\n",
    "ax2.imshow(wordcloud_trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombre de tweets par jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countplot = sns.catplot(kind='count',y='created_at', data=df_full.sort_values('mention'), hue='mention')\n",
    "countplot.set_xticklabels(rotation=80)\n",
    "colors = ['#258BF3','#F1120B','#25F347']\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "countplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombre de like par jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mpl_dates\n",
    "# Création d'un dataframe comptant le nombre de likes par jour pour chaque candidat à partir du dataframe complet\n",
    "df_graph_t = pd.DataFrame(df_full.loc[df_full['mention'] == 'Trump'].groupby('created_at')['likes'].sum())\n",
    "df_graph_b = pd.DataFrame(df_full.loc[df_full['mention'] == 'Biden'].groupby('created_at')['likes'].sum())\n",
    "df_graph_bt = pd.DataFrame(df_full.loc[df_full['mention'] == 'Trump & Biden'].groupby('created_at')['likes'].sum())\n",
    "\n",
    "# Jointure des dataframes\n",
    "df_graph = df_graph_t.join(df_graph_b, how='outer', on='created_at', lsuffix = '_trump', rsuffix = '_biden')\n",
    "df_graph = df_graph.join(df_graph_bt, how='outer', on='created_at', rsuffix = '_trump & biden')\n",
    "\n",
    "# Traçage du graphique\n",
    "date_format= mpl_dates.DateFormatter('%d/%m')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(df_graph.likes_trump / 1000, marker ='o',lw =2,linestyle='solid',markersize= 10, label = 'Trump', color = 'r')\n",
    "plt.plot(df_graph.likes_biden / 1000, marker ='o',lw =2,linestyle='solid',markersize= 10, color = 'b', label = 'Biden')\n",
    "plt.plot(df_graph.likes / 1000, marker ='o',lw =2,linestyle='solid',markersize= 10, color = 'g', label = 'Trump & Biden')\n",
    "plt.legend()\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('Nombre (k)')\n",
    "plt.title('Nombre de likes sur les Tweets mentionnant les candidats, selon le jour')\n",
    "plt.tight_layout()\n",
    "plt.gca().xaxis.set_major_formatter(date_format)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plateformes utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un nouveau dataframe ne contenant que les sources les plus populaires pour les Tweets\n",
    "df_sources = df_full[(df_full['source'] == 'Twitter for iPhone') | (df_full['source'] == 'Twitter for Android') \n",
    "                     | (df_full['source'] == 'Twitter Web App')].sort_values('mention')\n",
    "\n",
    "# Traçage du graphique\n",
    "countplot = sns.catplot(kind='count',x='source', data=df_sources, hue='mention')\n",
    "countplot.set_xticklabels(rotation = 80)\n",
    "colors = ['#258BF3','#25F347','#F1120B']\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "countplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombre de likes sur les tweets par état américain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "# Création d'un dataframe ne contenant que les tweets localisés aux États-Unis\n",
    "dtus= df_trump[df_trump.country == \"United States of America\"]\n",
    "\n",
    "# Filtrage des colonnes nécessaires\n",
    "dtus = dtus[['likes','retweet_count','state','state_code','country']]\n",
    "\n",
    "# Regroupement des likes par état puis conversion en dataframe car le resultat sortant est une série\n",
    "dtus_grouped = dtus.groupby('state_code')['likes'].sum()\n",
    "dtfinal = dtus_grouped.to_frame().reset_index()\n",
    "\n",
    "\n",
    "#Création de la carte choropleth\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=dtfinal['state_code'], # coordonnées spatiales\n",
    "    z = dtfinal['likes'].astype(float), # On associe la couleur au nombre de likes\n",
    "    locationmode = 'USA-states', \n",
    "    colorscale = 'turbo',\n",
    "    autocolorscale=False,\n",
    "    colorbar_title = \"Nombre de likes\",\n",
    "    zmin = 0,\n",
    "    zmax = 700000,\n",
    "    marker_line_color='white'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Nombre de like par état pour Trump',\n",
    "    geo_scope='usa', # centré sur les USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dataframe ne contenant que les tweets localisés aux États-Unis\n",
    "dbus = df_biden[df_biden.country==\"United States of America\"]\n",
    "\n",
    "# Filtrage des colonnes nécessaires\n",
    "dbus = dbus[['likes','retweet_count','state','state_code','country']]\n",
    "\n",
    "# Regroupement des likes par état puis conversion en dataframe car le resultat sortant est une série\n",
    "dbus_grouped = dbus.groupby('state_code')['likes'].sum()\n",
    "dbfinal = dbus_grouped.to_frame().reset_index()\n",
    "\n",
    "#Création de la carte choropleth\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations=dbfinal['state_code'], # coordonnées spatiales\n",
    "    z = dbfinal['likes'].astype(float), # On associe la couleur au nombre de likes\n",
    "    locationmode = 'USA-states', \n",
    "    colorscale = 'turbo',\n",
    "    autocolorscale=False,\n",
    "    colorbar_title = \"Nombre de likes\",\n",
    "    zmin = 0,\n",
    "    zmax = 700000,\n",
    "    marker_line_color='white'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Nombre de like par état pour Biden',\n",
    "    geo_scope='usa', # centré sur les USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Candidat ayant le plus de likes par état"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dataframe contenant le nombre de likes pour chaque candidat selon l'État\n",
    "df_likesperstate = dbfinal.join(dtfinal.set_index('state_code'),on='state_code', \n",
    "                                how='outer', lsuffix = '_biden',rsuffix='_trump')\n",
    "\n",
    "# Ajout d'une Série contenant le le candidat ayant le plus de likes pour chaque État\n",
    "df_likesperstate['gagnant'] = np.where(df_likesperstate['likes_trump'] > df_likesperstate['likes_biden'], 'Trump', 'Biden')\n",
    "\n",
    "# Traçage de la carte Choropleth\n",
    "fig = go.Figure(data=px.choropleth(\n",
    "    locations=df_likesperstate['state_code'], # coordonnées spatiales\n",
    "    color = df_likesperstate['gagnant'], # On associe la couleur au nombre de likes\n",
    "    locationmode = 'USA-states',\n",
    "    hover_data = ['likes_trump', 'likes_biden'],\n",
    "    data_frame = df_likesperstate\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = 'Gagnant par état selon le nombre de likes sur Twitter',\n",
    "    geo_scope='usa', # centré sur les USA\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
